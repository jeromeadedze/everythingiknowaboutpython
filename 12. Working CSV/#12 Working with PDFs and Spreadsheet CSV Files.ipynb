{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a01b5f6",
   "metadata": {},
   "source": [
    "## Working with CSV Files\n",
    "\n",
    "CSV stands for ***comma separated variables*** which is a common output for spreadsheet programs. These files are used in organizations for transmitting and storing data. They can be created in Notepad, Excel, etc...\n",
    "\n",
    "### Example (text file with data separated by commas)\n",
    "<img src = \"../img/csvexample.png\"\n",
    "     height= \"400px\"\n",
    "width= \"720px\">\n",
    "\n",
    "### Example (same text file when extension changed to .csv)\n",
    "<img src = \"../img/csvexample1.png\"\n",
    "     height= \"400px\"\n",
    "width= \"720px\">\n",
    "\n",
    "NB: \n",
    "- All CSV files are just plain texts(meaning they can be opened and read using any text editor or word processor), \n",
    "- they contain alphanumeric characters, \n",
    "- they of lines of text, with each line representing a row of data in the table. Within each line, the values are separated by commas (hence the name \"comma-separated\").\n",
    "- While CSV files can be opened and edited in programs like Excel, they are not the same format. CSV files do not have the advanced formatting capabilities of Excel files, such as font styles, colors, formulas, or data types. This means that in a CSV file, all values are treated as strings ***(meaning there is no inherent distinction between numbers, dates, or other data types within a CSV file)***. As a result, when opening a CSV file in a program like Excel, all values are initially treated as plain text.\n",
    "\n",
    "---\n",
    "\n",
    "Python has a built in csv module that will allows us to grab columns rows,and values from a .csv file as well as write to it.\n",
    "\n",
    "There are other libraries to consider for working with csv files\n",
    "1. Pandas\n",
    "    - It is a full data analysis library\n",
    "    - Runs visualizations and analysis\n",
    "2. Openpyxl\n",
    "    - designed specifically for Excel files\n",
    "3. Google Sheets Python API\n",
    "\n",
    "### Lets explore python's built-in library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaccbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT CSV\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cdefa3",
   "metadata": {},
   "source": [
    "## Reading CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e27855c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN THE FILE\n",
    "csv_file = open(\"example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cedb20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALL csv.reader on the file\n",
    "csv_reader = csv.reader(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf97aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFORMAT it into a python object using list( )\n",
    "data_lines = list(csv_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2c298",
   "metadata": {},
   "source": [
    "#### Sometimes after running the previous line of code you might get an error.\n",
    "<img src = \"../img/unicodeerror.png\"\n",
    "     height= \"400px\"\n",
    "width= \"720px\">\n",
    "\n",
    "The error message means that there is a problem when trying to convert a sequence of bytes into readable text. The specific issue is related to a character in the byte sequence that cannot be understood by the default decoding method used on Windows systems.\n",
    "\n",
    "To fix this issue, you add an ***encoding argument*** when opening the file and specify an encoding.\n",
    "\n",
    "In a situation where you do not get this error it just means your computer's defautlt encoding matches the file.\n",
    "\n",
    "##### Let's try this again...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "732d0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN THE FILE (THIS TIME WE ADD AN ENCODING ARGUMENT)\n",
    "csv_file = open(\"example.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7702847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALL csv.reader on the file\n",
    "csv_reader = csv.reader(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e070dd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.reader at 0x7fd272353660>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f913bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFORMAT it into a python object using list ( )\n",
    "data_lines = list(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62f49bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280c0bb",
   "metadata": {},
   "source": [
    "When we check the result of ***data_lines***, we get a ***list of lists***(data structure that represents a collection of lists where each element in the main list is itself a separate list)\n",
    "\n",
    "- The first item is the column names\n",
    "- The second and remaining items are the data rows\n",
    "<img src = \"../img/data_lines.png\"\n",
    "     height= \"400px\"\n",
    "width= \"720px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cdb5a9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'first_name', 'last_name', 'email', 'gender', 'ip_address', 'city']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking column names\n",
    "data_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "acaa72c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows \n",
    "# (basically total items - 1) since one item represents the column\n",
    "len(data_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d3e326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'first_name', 'last_name', 'email', 'gender', 'ip_address', 'city']\n",
      "['1', 'Joseph', 'Zaniolini', 'jzaniolini0@simplemachines.org', 'Male', '163.168.68.132', 'Pedro Leopoldo']\n",
      "['2', 'Freida', 'Drillingcourt', 'fdrillingcourt1@umich.edu', 'Female', '97.212.102.79', 'Buri']\n",
      "['3', 'Nanni', 'Herity', 'nherity2@statcounter.com', 'Female', '145.151.178.98', 'Claver']\n",
      "['4', 'Orazio', 'Frayling', 'ofrayling3@economist.com', 'Male', '25.199.143.143', 'Kungur']\n"
     ]
    }
   ],
   "source": [
    "# To get a nice format (use a for loop)\n",
    "# I used index slicing here since the list to too long\n",
    "for line in data_lines[:5]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46ecdb",
   "metadata": {},
   "source": [
    "### We can extract any item in the csv file \n",
    "#### we can extract....\n",
    "- a row\n",
    "- an item in row\n",
    "- an item in a column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16191af7",
   "metadata": {},
   "source": [
    "## Writing a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abf50266",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"first_csv_file\",mode = \"w\", newline = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed09c2",
   "metadata": {},
   "source": [
    "#### This creates a file if the file name did not exist in the directory / It will overwrite any exisiting file with the same name\n",
    "\n",
    "<img src = \"../img/firstcsvfile.png\"\n",
    "     height= \"400px\"\n",
    "width= \"720px\">\n",
    "\n",
    "You may have noticed the newline argument, the ***newline parameter*** in Python controls how line endings are handled when reading or writing text files. \n",
    "\n",
    "NB: It applies to text mode only.(not applicable binary mode)\n",
    "\n",
    "\n",
    "- If \"newline\" is set to None or an empty string (''), Python will automatically convert different line ending formats (like '\\n', '\\r', or '\\r\\n') into a single '\\n' character. So, regardless of the line ending format in the input file, Python will make it consistent and use '\\n' as the line ending representation in the returned data.\n",
    "- If \"newline\" has any other value (e.g., '\\r' or '\\r\\n'), Python will consider lines terminated only by that specific string. The line endings will be returned exactly as they are in the input file.\n",
    "\n",
    "By explicitly setting `newline=''` when opening the file, you ensure that the correct line termination is used when writing rows with `csv_writer.writerow()`. \n",
    "This is important for maintaining compatibility with different operating systems and preventing issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef3bd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call csv.writer(object) on the file\n",
    "csv_writer = csv.writer(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "427d9d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writing a single row\n",
    "csv_writer.writerow([\"Name\",\"Age\",\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "477e5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing mutiple rows (This takes in a list of lists)\n",
    "# Number of items in rows must be consistent\n",
    "csv_writer.writerows([[\"Selorm\",17,11],[\"Jerome\",19,13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e9dccc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8daff",
   "metadata": {},
   "source": [
    "### You should see this when you open the file\n",
    "<img src = \"../img/firstcsvfile1.png\"\n",
    "     height= \"400px\"\n",
    "width= \"720px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654a849",
   "metadata": {},
   "source": [
    "## Working with PDF files\n",
    "\n",
    "PDF stands for Portable Document Format which was developed by Adobe.\n",
    "\n",
    "Most PDFs that contain scanned documents or images are not machine-readable. Scanned PDFs are essentially images or pictures of documents, and they lack structured text data that can be easily extracted and processed by Python.\n",
    "\n",
    "We are going to use a free open source library ***PyPDF2*** to read and extract pdfs.\n",
    "\n",
    "NB: remember that most pdfs are not machine readable\n",
    "\n",
    "### Working with PyPDF2\n",
    "\n",
    "The first thing you need to do is install the PyPDF2 at your command line using `pip install PyPDF2`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeeb4d8",
   "metadata": {},
   "source": [
    "### Reading PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424f969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the PyPDF2 library\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d28a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open PDF file\n",
    "f = open(\"Working_Business_Proposal.pdf\", mode = \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e2dda",
   "metadata": {},
   "source": [
    "### 'Why rb' mode is necessary\n",
    "A pdf file is not just plain text, so it needs to be opened in binary mode. There will be characters in the file that can't be interpreted as plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "977afa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the PyPDF2.PdfFileReader( object_name )\n",
    "pdf_reader = PyPDF2.PdfReader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecfc733b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of pages in the pdf\n",
    "len(pdf_reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a0fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a specific page\n",
    "page_one = pdf_reader.pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6b93708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting text from page one\n",
    "page_one_text = page_one.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73c4b409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business Proposal The Revolution is Coming Leverage agile frameworks to provide a robust synopsis for high level overviews. Iterative approaches to corporate strategy foster collaborative thinking to further the overall value proposition. Organically grow the holistic world view of disruptive innovation via workplace diversity and empowerment. Bring to the table win-win survival strategies to ensure proactive domination. At the end of the day, going forward, a new normal that has evolved from generation X is on the runway heading towards a streamlined cloud solution. User generated content in real-time will have multiple touchpoints for offshoring. Capitalize on low hanging fruit to identify a ballpark value added activity to beta test. Override the digital divide with additional clickthroughs from DevOps. Nanotechnology immersion along the information highway will close the loop on focusing solely on the bottom line. Podcasting operational change management inside of workﬂows to establish a framework. Taking seamless key performance indicators ofﬂine to maximise the long tail. Keeping your eye on the ball while performing a deep dive on the start-up mentality to derive convergence on cross-platform integration. Collaboratively administrate empowered markets via plug-and-play networks. Dynamically procrastinate B2C users after installed base beneﬁts. Dramatically visualize customer directed convergence without revolutionary ROI. Efﬁciently unleash cross-media information without cross-media value. Quickly maximize timely deliverables for real-time schemas. Dramatically maintain clicks-and-mortar solutions without functional solutions. BUSINESS PROPOSAL!1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_one_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52c5b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266cd7c",
   "metadata": {},
   "source": [
    "### Adding to PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d485cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2fb4ba8",
   "metadata": {},
   "source": [
    "### Links:\n",
    "\n",
    "### CSV\n",
    "https://www.educba.com/csv-files-into-excel/\n",
    "\n",
    "### Unicode\n",
    "https://www.twilio.com/docs/glossary/what-is-unicode\n",
    "\n",
    "#### Character Encoding\n",
    "https://www.motionpoint.com/blog/the-importance-of-character-encoding-website-translation-user-experience/#:~:text=What%20is%20Character%20Encoding%3F,a%20letter%2C%20number%20or%20symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d50386",
   "metadata": {},
   "source": [
    "### Misc:\n",
    "\n",
    "#### Character Encoding\n",
    "\n",
    "***Unicode*** is an international character encoding standard that provides a unique number for every character across languages and scripts, making almost all characters accessible across platforms, programs, and devices.\n",
    "\n",
    "***Character encoding*** is the process of representing individual characters(especially the written characters of human language) using a corresponding encoding system made up of other symbols and types of data. \n",
    "\n",
    "- It tells computers how to interpret digital data into letters, numbers and symbols. This is done by assigning a specific numeric value to a letter, number or symbol.\n",
    "\n",
    "- It is a way to convert text data into binary numbers.\n",
    "\n",
    "A ***codec*** is short for coder/decoder is a chip that decodes analog-to-digital conversion and digital-to-analog."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
